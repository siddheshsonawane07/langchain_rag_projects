{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom function for loading and splitting json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def split_json_by_quotes(data, chunk_size=3):\n",
    "    chunks = []\n",
    "    current_chunk = {}\n",
    "    current_category = None\n",
    "    count = 0\n",
    "    \n",
    "    for category, quotes in data.items():\n",
    "        if not current_chunk.get(category):\n",
    "            current_chunk[category] = []\n",
    "        \n",
    "        for quote in quotes:\n",
    "            current_chunk[category].append(quote)\n",
    "            count += 1\n",
    "            \n",
    "            if count >= chunk_size:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = {category: []}\n",
    "                count = 0\n",
    "    \n",
    "    if current_chunk and any(current_chunk.values()):\n",
    "        chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Load JSON data from file\n",
    "try:\n",
    "    with open(\"shayari_data.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        shayari_data = json.load(file)\n",
    "\n",
    "    # Split data into chunks of 3 quotes each\n",
    "    split_data = split_json_by_quotes(shayari_data, chunk_size=3)\n",
    "\n",
    "    # for idx, chunk in enumerate(split_data):\n",
    "    #     print(f\"Chunk {idx + 1}:\", json.dumps(chunk, ensure_ascii=False, indent=4))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting the split data (chunks) into format that is suitable for vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document  \n",
    "\n",
    "# Convert the split data to the Document format\n",
    "documents = []\n",
    "for chunk in split_data:\n",
    "    for category, quotes in chunk.items():\n",
    "        for quote in quotes:\n",
    "            # Create a text representation of each quote\n",
    "            text_content = f\"{quote['quote']} - {quote['author']}\"\n",
    "            documents.append(Document(page_content=text_content, metadata={\"category\": category}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embed = OllamaEmbeddings(\n",
    "    model=\"llama3.2\"\n",
    ")\n",
    "vector_store = Chroma.from_documents(documents=documents, embedding= embed)\n",
    "print(len(vector_store))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "local_llm = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {question}\"\"\")\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are a few shayaris (poems) in Hindi from the provided context:\\n\\n1. दोस्त एक दर्द है, दोस्त एक मरहम है - फिराक गोरखपुरी\\n2. इश्क की इंतहा अजीब दास्तान है, यह कहां से शुरू, कहां से ख़तम।'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"fetch some shayaris from context\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
